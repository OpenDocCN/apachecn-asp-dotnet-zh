# 扩展微服务

假设您是负责开发公司旗舰产品 TaxCloud 的开发和支持团队的一员。TaxCloud 帮助纳税人自行报税，并在成功报税后向他们收取少量费用。假设您使用微服务开发了这个应用程序。现在，假设产品变得受欢迎并获得吸引力，突然，在纳税申报的最后一天，你会看到一群消费者想要使用你的产品并申报纳税。但是你的系统支付服务比较慢，几乎把系统拖垮了，新客户都转移到你竞争对手的产品上了。这对你的生意来说是一个失去的机会。

尽管这是一个虚构的场景，但它很可能发生在任何企业。在电子商务中，我们在现实生活中总是会经历这种事情，尤其是在圣诞节和黑色星期五这样的特殊场合。总而言之，它们指向一个重要的特征——系统的可伸缩性。可扩展性是任何任务关键型系统最重要的非功能性需求之一。用几百个事务服务几个用户并不等于用几百万个事务服务几百万个用户。在本章中，我们将一般性地讨论可伸缩性。我们还将讨论如何单独扩展微服务，在设计它们时要考虑什么，以及如何使用不同的模式来避免级联故障。到本章结束时，您将了解到:

*   水平缩放
*   垂直缩放
*   可伸缩性的尺度立方体模型
*   使用 Azure 扩展集和 Docker Swarm 扩展基础架构
*   通过数据模型缓存和响应缓存扩展服务设计
*   断路器模式
*   服务发现

# 可扩展性概述

设计决策会影响单个微服务的可扩展性。与其他应用程序功能一样，在设计和早期编码阶段做出的决策在很大程度上影响服务的可伸缩性。

微服务的可伸缩性要求在服务及其支持基础设施之间采取平衡的方法。服务及其基础设施也需要协调扩展。

可伸缩性是系统最重要的非功能特性之一，因为它可以处理更多的负载。人们通常认为可伸缩性通常是大规模分布式系统的一个关注点。性能和可伸缩性是系统的两个不同特征。性能处理系统的吞吐量，而可伸缩性处理为大量用户或大量事务提供所需的吞吐量。

# 扩展基础设施

微服务是现代应用程序，通常利用云。因此，在可扩展性方面，云提供了一定的优势。然而，这也是关于自动化和管理成本。因此，即使在云中，我们也需要了解如何调配基础架构，例如虚拟机或容器，以便即使在突发流量峰值的情况下也能成功地为我们基于微服务的应用程序提供服务。

现在，我们将访问基础架构的每个组件，看看我们如何扩展它。最初的纵向扩展和横向扩展方法更多地应用于硬件扩展。使用自动缩放功能，您将了解 Azure 虚拟管理器缩放集。最后，您将学习在 Docker Swarm 模式下使用容器进行缩放。

# 垂直扩展(向上扩展)

**纵向扩展**是一个术语，用于通过向同一台机器添加更多资源来实现可扩展性。它包括以更高的速度增加更多的内存或处理器，或者简单地将应用程序迁移到更强大的 macOS。

随着硬件的升级，您如何扩展机器是有限制的。更有可能的是，您只是在转移瓶颈，而不是解决提高可伸缩性的真正问题。如果你给机器增加更多的处理器，你可能会把瓶颈转移到内存上。处理能力不会线性提高系统的性能。在某一点上，即使您增加了更多的处理能力，系统的性能也会稳定下来。扩展的另一个方面是，由于只有一台机器服务于所有请求，它也成为单点故障。

总之，垂直缩放很容易，因为它不涉及代码更改；然而，这是一项相当昂贵的技术。堆栈溢出是基于. NET 的系统垂直扩展的罕见例子之一。

# 水平缩放(横向扩展)

如果不想垂直缩放，您可以始终水平缩放系统。通常，它也被称为**横向扩展**。谷歌确实让这种方法变得相当流行。谷歌搜索引擎已经没有便宜的硬件了。因此，尽管是一个分布式系统，但横向扩展在早期帮助谷歌在短时间内扩展了其搜索过程，同时成本低廉。大多数情况下，常见的任务被分配给工人机器，它们的输出由几台执行相同任务的机器收集。这种安排也会在失败中幸存下来。为了横向扩展，负载平衡技术非常有用。在这种布置中，负载平衡器通常被添加在所有节点集群的前面。因此，从消费者的角度来看，你击中的是哪台机器/盒子并不重要。这使得通过添加更多服务器来增加容量变得容易。将服务器添加到集群可以线性提高可扩展性。

当应用程序代码不依赖于运行它的服务器时，向外扩展是一种成功的策略。如果请求需要在特定的服务器上执行，也就是说，如果应用程序代码具有服务器关联性，将很难向外扩展。但是，在无状态代码的情况下，在任何服务器上执行该代码都更容易。因此，当无状态代码在水平扩展的机器或集群上运行时，可伸缩性得到了提高。

由于横向扩展的性质，它是整个行业中常用的方法。您可以看到许多以这种方式管理的大型可扩展系统的例子，例如谷歌、亚马逊和微软。我们建议您也以水平方式扩展微服务。

# 微服务可扩展性

在本节中，我们将回顾可用于微服务的扩展策略。我们将研究可伸缩性的 Scale Cube 模型，如何为微服务扩展基础设施层，以及在微服务设计中嵌入可伸缩性。

# 可伸缩性的尺度立方体模型

看待可伸缩性的一种方法是理解 Scale Cube。在《可伸缩性的艺术:现代企业的可伸缩网络架构、流程和组织》一书中，马丁·阿伯特和迈克尔·费希尔将尺度立方体定义为查看和理解系统可伸缩性。Scale Cube 也适用于微服务架构:

![](assets/2d5760c4-f65e-462d-8133-ddf0ba025fe9.png)

在这个可伸缩性的三维模型中，原点(0，0，0)代表最不可伸缩的系统。它假设系统是部署在单个服务器实例上的整体。如图所示，一个系统可以通过在三个维度上投入适当的努力来扩展。为了使系统朝着正确的可扩展方向发展，我们需要正确的权衡。这些权衡将帮助您获得系统的最高可扩展性。这将有助于您的系统满足不断增长的客户需求。这由**比例立方体**模型表示。让我们看看这个模型的每一个轴，并讨论它们在微服务可伸缩性方面意味着什么。

# x 轴的缩放

在 *x* 轴上扩展意味着在负载平衡器后面运行应用程序的多个实例。这是单片应用中非常常见的方法。这种方法的缺点之一是，应用程序的任何实例都可以利用该应用程序可用的所有数据。它也不能解决应用程序的复杂性。

微服务不应该共享一个全局状态或一种可以被所有服务访问的数据存储。这将造成瓶颈和单点故障。因此，仅在缩放立方体的 *x* 轴上进行微服务缩放不是正确的方法。

现在我们来看看 *z* 轴缩放。我们跳过了 *y* 轴缩放是有原因的。

# z 轴的缩放

*z* 轴缩放基于拆分，拆分基于交易的客户或请求者。虽然 *z* 轴拆分可以解决也可以不解决指令、进程或代码的整体性，但它们经常解决执行这些指令、进程或代码所需的数据的整体性。自然，在 *z* 轴缩放中，有一个专用组件负责应用偏置因子。偏见因素可能是国家、请求来源、客户群或与请求者或请求相关的任何形式的订阅计划。注意 *z* 轴缩放有很多好处，比如提高了请求的隔离和缓存；然而，它也有以下缺点:

*   它增加了应用程序的复杂性。
*   它需要一个分区方案，这可能很棘手，尤其是当我们需要重新分区数据时。
*   它没有解决开发和应用复杂性增加的问题。要解决这些问题，需要应用 *y* 轴缩放。

由于 *z* 轴缩放的前述性质，它不适合在微服务的情况下使用。

# y 轴的缩放

*y* 轴缩放基于应用程序到不同组件的功能分解。尺度立方体的 *y* 轴表示按角色或数据类型划分的责任，或事务中某个组件执行的工作。为了划分责任，我们需要根据系统组件所执行的操作或角色来划分它们。这些角色可能基于事务的大部分，也可能基于非常小的一部分。根据角色的大小，我们可以扩展这些组件。这种拆分方案被称为*服务或面向资源的拆分*。

这与我们在微服务中看到的非常相似。我们根据应用程序的角色或操作来划分整个应用程序，并根据其在系统中的角色来扩展单个微服务。这种相似不是偶然的；它是设计的产物。所以我们可以很公平的说 *y* 轴缩放非常适合微服务。

理解 *y* 轴扩展对于扩展基于微服务架构的系统非常重要。因此，实际上，我们是在说微服务可以通过根据它们的角色和动作来拆分它们来扩展。考虑一个订单管理系统，它被设计来，比如说，满足特定的初始客户需求；为此，将应用程序拆分为诸如客户服务、订单服务和支付服务这样的服务就可以了。但是，如果需求增加，您需要仔细检查现有系统。您可能会发现已经存在的服务的子组件，这些子组件可以很好地再次分离，因为它们在该服务和整个应用程序中扮演着非常特定的角色。这种针对增加的需求/负载的重新设计可能会触发将订单服务重新拆分为报价服务、订单处理服务、订单履行服务等。现在，报价服务可能需要更多的计算能力，因此与其他服务相比，我们可能会推送更多的实例(其背后的相同副本)。

这是一个近乎真实的例子，说明我们应该如何在 AFK Scale Cube 的三维模型上扩展微服务。你可以在一些属于行业的知名微服务架构中观察到这种三维可伸缩性和 *y* 轴的服务伸缩性，比如亚马逊、网飞、Spotify。

# 可扩展微服务的特征

在缩放立方体部分，我们主要关注于缩放整个系统或应用程序的特征。在本节中，我们将重点关注扩展单个微服务的特性。当微服务表现出以下主要特征时，可以说它是可扩展的和高性能的:

*   已知的增长曲线:例如，在订单管理系统的情况下，我们需要知道当前服务支持多少订单，以及它们与订单履行服务指标(以每秒*个请求*来衡量)的比例如何。当前测量的指标称为**基线数字**。
*   经过充分研究的使用指标:流量模式通常揭示客户需求，并且基于客户需求，可以计算出前面几节中提到的关于微服务的许多参数。因此，微服务是仪表化的，监控工具是微服务的必要伙伴。
*   基础设施资源的有效利用:基于定性和定量参数，可以对资源利用进行预测。这将有助于团队预测基础架构的成本并为其进行规划。
*   使用自动化基础架构测量、监控和增加容量的能力:基于微服务资源消耗的运营和增长模式，规划未来容量非常容易。如今，随着云的弹性，能够规划和自动化容量变得更加重要。本质上，基于云的架构是成本驱动的架构。
*   已知瓶颈:资源需求包括每个微服务需要的特定资源(计算、内存、存储和输入/输出)。识别这些对于更顺畅的运营和可扩展的服务至关重要。如果我们确定了资源瓶颈，就可以解决和消除它们。
*   具有相同比例的相关性缩放:这是不言自明的。然而，你不能只关注一个微服务，让它的依赖成为瓶颈。微服务的可伸缩性取决于其最小的伸缩依赖性。
*   容错性和高可用性:在分布式系统中，故障是不可避免的。如果遇到微服务实例故障，应该自动将其重新路由到健康的微服务实例。在这种情况下，仅仅将负载平衡器放在微服务集群前面是不够的。服务发现工具对于满足可扩展微服务的这一特性非常有帮助。
*   具有可扩展的数据持久性机制:对于可扩展的微服务，单个数据存储的选择和设计应该是可扩展和容错的。在这种情况下，缓存和分离读写存储会有所帮助。

现在，当我们讨论微服务和可伸缩性时，伸缩性的自然安排出现了，它只不过是以下内容:

*   扩展基础设施:微服务在动态和软件定义的基础设施上运行良好。因此，扩展基础设施是扩展微服务的重要组成部分。
*   围绕服务设计扩展:微服务设计包括一个基于 HTTP 的应用编程接口和一个存储服务本地状态的数据存储。

# 扩展基础设施

在本节中，我们将访问微服务基础架构的所有层，并查看它们之间的关系，即每个基础架构层如何扩展。在我们的微服务实现中，有两个主要组件。一个是虚拟机，另一个是托管在虚拟机或物理机上的容器。下图显示了微服务基础架构的逻辑视图:

![](assets/55de4676-81c0-41bd-82d4-1c02be78f4f0.png)

# 使用扩展集扩展虚拟机

在 Azure Cloud 中扩展虚拟机非常简单和容易。这是微服务闪耀的地方。使用扩展集，您可以根据规则集在短时间内自动提升相同虚拟机映像的实例。刻度集与 Azure 自动刻度集成在一起。

Azure 虚拟机可以以这样一种方式创建，即作为一个组，即使请求量增加，它们也始终为请求提供服务。在特定情况下，如果不需要这些虚拟机来执行工作负载，也可以自动删除它们。这由虚拟机规模集负责。

秤台也能与 Azure 中的负载平衡器很好地集成。由于它们被表示为计算资源，因此可以与 Azure 的资源管理器一起使用。可以配置扩展集，以便按需创建或删除虚拟机。这有助于以`pets vs. cattle`的心态来管理虚拟机，我们在本章前面的部署部分看到了这一点。

对于需要扩展计算资源的应用程序，扩展操作在故障域和更新域之间是隐式平衡的。

使用扩展集，您不需要关联独立资源的循环，如网卡、存储帐户和虚拟机。即使是横向扩展，我们如何解决这些虚拟经理的可用性问题？虚拟机规模集已经解决了所有这些问题和挑战。

扩展集允许您根据需求自动扩展和缩减应用程序。假设有一个 40%利用率的阈值。因此，一旦我们达到 40%的利用率，我们将开始经历性能下降。利用率达到 40%时，就会增加新的 web 服务器。如前几节所述，比例集允许您设置规则。规模集的输入是虚拟机。规模集上的规则规定，在平均 40%的 CPU 上，五分钟内，Azure 将向规模集中添加另一台虚拟机。执行此操作后，再次校准规则。如果性能仍高于 40%，请添加第三个虚拟机，直到达到可接受的阈值。一旦性能下降到 40%以下，它将开始根据流量不活动等情况删除这些虚拟机，以降低运营成本。

因此，通过实现一个扩展集，您可以为性能构建一个规则，并通过简单地自动添加和删除虚拟机来使您的应用程序更大，以处理更大的负载。一旦建立了这些规则，作为管理员的你将无事可做。

Azure Autoscale 测量性能并确定何时向上和向下扩展。它还集成了负载平衡器和网络地址转换。现在，它们与负载平衡器和网络地址转换集成在一起的原因是，当我们添加这些额外的虚拟机时，前面会有一个负载平衡器和一个网络地址转换设备。随着请求不断传入，除了部署虚拟机之外，我们还必须添加一个允许流量重定向到新实例的规则。扩展集的伟大之处在于，它们不仅可以添加虚拟机，还可以与基础架构的所有其他组件协同工作，包括网络负载平衡器等。

在 Azure 门户中，一个扩展集可以被视为一个条目，即使它包含多个虚拟机。要查看扩展集中虚拟机的配置和规范细节，您必须使用 Azure 资源浏览器工具。这是一个基于网络的工具，可在 https://resources.azure.com 获得。在这里，您可以查看订阅中的所有对象。您可以在 Microsoft 中查看比例集。计算部分。

使用 Azure 模板库构建一个比例集非常容易。一旦您创建了自己的 **Azure 资源管理器** ( **ARM** )模板，您也可以基于比例集创建自定义模板。由于范围和空间的限制，我们省略了关于如何构建比例集的详细讨论和说明。您可以使用在[https://github.com/gbowerman/azure-myriad](https://github.com/gbowerman/azure-myriad)提供的 ARM 模板遵循这些说明。

An availability set is an older technology, and this feature has limited support. Microsoft recommends that you migrate to virtual machine scale sets for faster and more reliable autoscale support.

# 自动缩放

借助监控解决方案，我们可以测量基础架构的性能参数。这通常是以性能 SLa 的形式。自动扩展使我们能够根据性能阈值增加或减少系统可用的资源。

自动缩放功能增加了额外的资源，以适应增加的负载。它的工作原理也相反。如果负载降低，则自动缩放会减少可用于执行任务的资源数量。自动扩展无需预先配置资源即可完成所有工作，并且是以自动方式完成的。

自动缩放可以通过两种方式进行缩放-纵向(向现有资源类型添加更多资源)或横向(通过创建该类型资源的另一个实例来添加资源)。

自动缩放功能根据两种策略决定添加或删除资源。一种是基于资源的可用指标或满足某个系统阈值。另一种策略是基于时间的，例如，在 IST 早上 9 点到下午 5 点之间，而不是三个网络服务器；该系统需要 30 台网络服务器。

蔚蓝监测仪器的每一个资源；收集并监控所有与指标相关的数据。根据收集的数据，自动缩放做出决策。

Azure Monitor 自动扩展仅适用于虚拟机扩展集、云服务和应用服务(例如，网络应用)。

# 使用 Docker Swarm 进行容器缩放

早些时候，在关于部署的一章中，我们研究了如何将微服务打包到 Docker 容器中。我们还详细讨论了为什么容器化在微服务领域很有用。在这一节中，我们将利用 Docker 来提升我们的技能，并看看我们如何利用 Docker Swarm 轻松扩展我们的微服务。

从本质上讲，微服务是分布式系统，需要分布式和隔离的资源。Docker Swarm 提供容器编排集群功能，以便多个 Docker 引擎可以作为单个虚拟引擎工作。这类似于负载平衡器功能；此外，如果需要，它还会创建新的容器实例或删除容器。

您可以使用任何可用的服务发现机制，如域名系统、咨询或动物园管理员工具。

集群是 Docker 引擎或节点的集群，在这里您可以将微服务部署为*服务*。现在，不要将这些服务与微服务混淆。在 Docker 实现中，服务是一个不同的概念。一个**服务**是要在工作节点上执行的任务的定义。您可能想了解我们在最后一句中提到的节点。Docker Swarm 上下文中的节点用于参与集群的 Docker 引擎。一个完整的群体演示是可能的，ASP.NET 核心图像可在 ASP。GitHub([https://github.com/aspnet/aspnet-docker](https://github.com/aspnet/aspnet-docker))上的 NET-Docker 项目。

The Azure Container Service has recently been made available. It is a good solution for scaling and orchestrating Linux or Windows containers using DC/OS, Docker Swarm, or Google Kubernetes.

既然我们已经了解了如何扩展微服务基础设施，那么让我们在接下来的章节中重新讨论微服务设计的可扩展性方面。

# 扩展服务设计

在这些部分中，我们将了解在设计或实现微服务时需要注意的组件/问题。在基础架构扩展考虑到服务设计的情况下，我们可以真正释放微服务架构的力量，并在使微服务成为真正的成功案例方面获得大量业务价值。那么，服务设计的组成部分是什么？让我们看看。

# 数据持久化模型设计

在传统应用程序中，我们一直依赖关系数据库来保存用户数据。关系数据库对我们来说并不陌生。它们出现在 70 年代，作为一种以结构化方式存储持久信息的方式，允许您进行查询和执行数据维护。

在当今的微服务世界中，现代应用需要在超大规模阶段进行扩展。我们在这里不建议您在任何意义上放弃使用关系数据库。他们仍然有他们的有效用例。然而，当我们在单个数据库中混合读写操作时，在我们需要提高可伸缩性的地方就会出现复杂的情况。关系数据库强化关系并确保数据的一致性。关系数据库工作在众所周知的 ACID 模型上。因此，在关系数据库中，我们对读取和写入操作使用相同的数据模型。

然而，读和写操作的需求是完全不同的。在大多数情况下，读操作通常必须比写操作快。读取操作也可以使用不同的筛选条件来完成，返回单行或结果集。在大多数写操作中，只涉及一行或一列，通常，与读操作相比，写操作花费的时间稍长。因此，我们可以在同一个数据模型中优化和服务读取或者优化和服务写入。

不如我们将基本数据模型分成两半:一个用于所有读操作，另一个用于所有写操作？现在事情变得简单多了，用不同的策略优化两个数据模型变得很容易。这对我们的微服务的影响是，反过来，它们对于这两种操作都变得高度可扩展。

这种特殊的架构被称为**公共查询责任隔离** ( **CQRS** )。自然的结果是，CQRS 也在我们的编程模型方面得到了扩展。现在，我们的编程模型之间的数据库-对象关系变得更加简单和可伸缩。

随之而来的是扩展微服务实现的下一个基本要素:数据缓存。

# 缓存机制

缓存是增加应用程序吞吐量的最简单方法。原理很简单。一旦从数据存储器中读取了数据，它就尽可能地靠近处理服务器。在未来的请求中，数据直接从数据存储或缓存中提供。缓存的本质是最小化服务器必须做的工作量。HTTP 在协议本身中嵌入了内置的缓存机制。这就是它伸缩性如此之好的原因。

对于微服务，我们可以在三个级别进行缓存，即客户端、代理和服务器端。让我们看看他们每个人。

首先，我们有客户端缓存。通过客户端缓存，客户端存储缓存的结果。所以客户端负责缓存失效。通常，服务器使用缓存控制和到期头等机制，提供关于它可以保留数据多长时间以及何时可以请求新数据的指导。随着浏览器支持 HTML5 标准，有更多的机制可用，例如本地存储、应用程序缓存或 web SQL 数据库，客户端可以在其中存储更多的数据。

接下来，我们进入代理端。许多反向代理解决方案，如 Squid、HAProxy 和 NGINX，也可以充当缓存服务器。

现在让我们详细讨论服务器端缓存。在服务器端缓存中，我们有以下两种类型:

*   响应缓存:这是 web 应用程序 UI 的一种重要的缓存机制，老实说，它也很简单，容易实现。为了响应缓存，与缓存相关的头被添加到微服务提供的响应中。这可以极大地提高微服务的性能。在 ASP.NET 核心中，您可以使用`Microsoft.AspNetCore.ResponseCaching`包实现响应缓存。
*   持久化数据的分布式缓存:分布式缓存增强了微服务的吞吐量，因为缓存不需要对任何外部资源进行输入/输出。这有以下优点:

    *   微服务客户端得到完全相同的结果。
    *   分布式缓存由持久性存储备份，并作为不同的远程进程运行。因此，即使应用服务器重新启动或出现任何问题，也绝不会影响缓存。
    *   对源数据存储的请求较少。

您可以在集群模式下使用分布式提供程序，如 CacheCow、Redis(对于我们的书 *Azure Redis Cache* )或 Memcache 来扩展您的微服务实现。

在下一节中，我们将概述 CacheCow 和 Azure Redis 缓存。

# CacheCow

当您想在客户机和服务器上实现 HTTP 缓存时，CacheCow 就出现了。这是一个轻量级库，目前，ASP.NET 网络应用编程接口支持是可用的。CacheCow 是开源的，并带有麻省理工学院的许可，可在 GitHub([https://github.com/aliostad/CacheCow](https://github.com/aliostad/CacheCow))[上获得。](https://github.com/aliostad/CacheCow)

要开始使用 CachCow，您需要为服务器和客户端做好准备。重要的步骤是:

*   在您的 ASP.NET 网络应用编程接口项目中安装`Install-Package CacheCow.Server` NuGet 包；这将是你的服务器。
*   在您的客户端项目中安装`Install-Package CacheCow.Client` NuGet 包；客户端应用程序将是 WPF、Windows 窗体、控制台或任何其他网络应用程序。
*   创建缓存存储。您需要在服务器端创建一个缓存存储，它需要一个用于存储缓存元数据的数据库([https://github . com/aliostad/CacheCow/wiki/入门#cache-store](https://github.com/aliostad/CacheCow/wiki/Getting-started#cache-store) )。

If you want to use memcache, refer to [https://github.com/aliostad/CacheCow/wiki/Getting-started](https://github.com/aliostad/CacheCow/wiki/Getting-started) for more information.

# 蓝色里兹高速缓存

Azure Redis Cache 建立在一个名为**Redis**([https://github.com/antirez/redis](https://github.com/antirez/redis))的开源基础之上，这是一个内存中的数据库，保存在磁盘上。根据微软([https://azure.microsoft.com/en-in/services/cache/](https://azure.microsoft.com/en-in/services/cache/)):

"Azure Redis Cache is based on the popular open source Redis cache. It gives you access to a secure, dedicated Redis cache, managed by Microsoft and accessible from any application within Azure."

借助以下步骤，开始使用 Azure Redis 缓存非常简单:

1.  创建一个网络应用编程接口项目——参考我们在[第 2 章](02.html)、*实现微服务*中的代码示例。
2.  实施 Redis 对于推荐点，使用[https://github.com/StackExchange/StackExchange.Redis](https://github.com/StackExchange/StackExchange.Redis)并安装`Install-Package StackExchange.Redis` NuGet 包。
3.  更新你的`CacheConnection`配置文件。
4.  然后在 Azure 上发布([https://docs . Microsoft . com/en-us/Azure/redis-cache/cache-web-app-how to # publish-the-application-to-Azure](https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#publish-the-application-to-azure))。

You can also use this template to create Azure Redis Cache:
 [https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-redis-cache-sql-database](https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-redis-cache-sql-database) For complete details on Azure Redis Cache refer to this URL:
 [https://docs.microsoft.com/en-us/azure/redis-cache/](https://docs.microsoft.com/en-us/azure/redis-cache/)

# 冗余和容错

我们知道，系统处理故障和从故障中恢复的能力与可伸缩性提供的能力不同。然而，我们不能否认，就系统而言，它们是密切相关的能力。除非我们解决可用性和容错的问题，否则构建高度可扩展的系统将是一项挑战。一般来说，我们通过为系统的不同部分/组件提供冗余副本来实现可用性。因此，在接下来的部分，我们将触及两个这样的概念。

# 断路器

断路器是电子设备中的一种安全功能，在发生短路时，它可以切断电流并保护设备，或者防止对周围环境造成任何进一步的损害。这个确切的想法可以应用于软件设计。当从属服务不可用或不处于健康状态时，断路器会阻止呼叫转到该从属服务，并在配置的时间段内将流量重定向到备用路径。

在他的名著《发布吧！设计和部署生产就绪软件，迈克尔·尼加德给出了断路器的详细信息。下图显示了典型的断路器模式:

![](assets/83e7a3c1-1650-48ec-b0a7-93ba4e863052.png)

如图所示，断路器充当具有三种状态的状态机。

# 关闭状态

这是电路的初始状态，描述了正常的控制流程。在这种状态下，有一个失败计数器。如果在该流程中出现`OperationFailedException`，故障计数器增加`1`。如果故障计数器持续增加，意味着电路遇到更多异常，并达到设定的故障阈值，断路器转换到*打开*状态。但是如果调用成功，没有任何异常或失败，失败计数将被重置。

# 开放状态

在*打开*状态下，电路已经跳闸，超时计数器已经启动。如果达到超时时间，电路仍然继续出现故障，代码流将进入半开状态。

# 半开状态

在半开路状态下，状态机/断路器组件重置超时计数器，并再次尝试断开电路，重新将状态更改为开路状态。但是，在此之前，它会尝试执行常规操作，比如调用依赖项；如果成功，则断路器组件将状态更改为关闭，而不是打开状态。这是为了使操作的正常流程能够发生，并且电路再次闭合。

For .NET-based microservices, if you want to implement the circuit breaker and a couple of fault-tolerant patterns, there is a good library named *Polly* available in the form of a NuGet package. It comes with extensive documentation and code samples, and moreover, has a fluent interface. You can add *Polly* from [http://www.thepollyproject.org/](http://www.thepollyproject.org/) or by just issuing the `install--Package Polly` command from the package manager console in Visual Studio.

# 服务发现

对于一个小的实现，如何确定微服务的地址？对任何人来说。NET 开发人员，答案是我们只需将 IP 地址和服务端口放在配置文件中，我们就好了。然而，当您在运行时动态地处理成百上千个服务时，就会出现服务位置问题。

现在，如果你看得更深一点，我们试图解决问题的两个部分:

*   服务注册:这是在某种中央注册中心内的注册过程，所有服务级别元数据、主机列表、端口和机密都存储在该注册中心。
*   服务发现:通过集中的注册组件在运行时建立依赖关系的通信就是服务发现。

任何服务注册和发现解决方案都需要具备以下特征，才能成为微服务发现问题的重要解决方案:

*   集中式注册表本身应该是高度可用的
*   一旦特定的微服务启动，它应该会自动接收请求
*   智能和动态负载平衡功能应该存在于解决方案中
*   该解决方案应该能够监控服务健康状态的能力及其承受的负载
*   服务发现机制应该能够将流量从不健康的节点转移到其他节点或服务，而不会造成任何宕机或对其使用者造成影响
*   如果服务位置或元数据发生变化，服务发现解决方案应该能够在不影响现有流量或服务实例的情况下应用这些变化

开源社区中有一些服务发现机制。它们如下:

*   Zookeeper:Zookeeper([http://zookeeper.apache.org/](http://zookeeper.apache.org/))是一个集中的服务，用于维护配置信息和命名，提供分布式同步，并提供组服务。它是用 Java 编写的，非常一致(CP)，并且使用 Zab([http://www.stanford.edu/class/cs347/reading/zab.pdf](http://www.stanford.edu/class/cs347/reading/zab.pdf))协议来协调整个集合(集群)的变化。
*   执政官:执政官使服务通过域名系统或超文本传输协议接口注册自己和发现其他服务变得简单。它还注册外部服务，如 SaaS 提供商。它还以键值的形式充当集中的配置存储。它还具有故障检测属性。它基于点对点的八卦协议。
*   Etcd: Etcd 是一个高度可用的键值存储，用于共享配置和服务发现。它的灵感来自动物园管理员和杜泽。用 Go 写的，用 Raft([https://ram cloud . Stanford . edu/wiki/download/attachments/11370504/Raft . pdf](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf))达成共识，有基于 HTTP+JSON 的 API。

# 摘要

可扩展性是追求微服务架构风格的关键优势之一。我们研究了微服务可伸缩性的特征。我们讨论了可伸缩性的 Scale Cube 模型，以及微服务如何通过系统的功能分解在 *y* 轴上伸缩。然后，我们通过扩展基础架构来解决扩展问题。在基础架构领域，我们看到了 Azure Cloud 强大的扩展能力，利用了 Azure 扩展集和容器编排解决方案，如 Docker Swarm、DC/操作系统和 Kubernetes。

在本章的后面阶段，我们将重点放在服务设计的扩展上，并讨论了应该如何设计我们的数据模型。我们还讨论了某些注意事项，例如在设计高可伸缩性的数据模型时，使用分离的 CQRS 风格模型。我们还简单介绍了缓存，尤其是分布式缓存，以及它如何提高系统的吞吐量。在最后一节中，为了使我们的微服务具有高度可伸缩性，我们讨论了断路器模式和服务发现机制，它们对于微服务架构的可伸缩性至关重要。

在下一章中，我们将研究微服务的反应性和反应性微服务的特征。